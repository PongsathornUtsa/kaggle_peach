{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-17T09:44:43.788766Z","iopub.execute_input":"2024-07-17T09:44:43.789262Z","iopub.status.idle":"2024-07-17T09:44:43.795946Z","shell.execute_reply.started":"2024-07-17T09:44:43.789232Z","shell.execute_reply":"2024-07-17T09:44:43.794951Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:44:43.797987Z","iopub.execute_input":"2024-07-17T09:44:43.798384Z","iopub.status.idle":"2024-07-17T09:44:46.382319Z","shell.execute_reply.started":"2024-07-17T09:44:43.798331Z","shell.execute_reply":"2024-07-17T09:44:46.381434Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:44:46.384288Z","iopub.execute_input":"2024-07-17T09:44:46.384618Z","iopub.status.idle":"2024-07-17T09:44:46.402226Z","shell.execute_reply.started":"2024-07-17T09:44:46.384593Z","shell.execute_reply":"2024-07-17T09:44:46.401288Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 785 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df, validation_df = train_test_split(df, test_size=0.2, random_state=3)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:44:46.404001Z","iopub.execute_input":"2024-07-17T09:44:46.404391Z","iopub.status.idle":"2024-07-17T09:44:46.628426Z","shell.execute_reply.started":"2024-07-17T09:44:46.404334Z","shell.execute_reply":"2024-07-17T09:44:46.627416Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class MNISTDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]  \n        image = np.array(row.iloc[1:], dtype=np.uint8).reshape(28, 28, 1)\n        label = row.iloc[0]  \n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n    def plot_image(self, idx):\n        image, label = self.__getitem__(idx)\n        image = image.numpy().squeeze()  \n        plt.imshow(image, cmap='gray')\n        plt.title(f'Label: {label}')\n        plt.axis('off')  \n        plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:44:46.630611Z","iopub.execute_input":"2024-07-17T09:44:46.630915Z","iopub.status.idle":"2024-07-17T09:44:46.639098Z","shell.execute_reply.started":"2024-07-17T09:44:46.630887Z","shell.execute_reply":"2024-07-17T09:44:46.638156Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\nfrom torchvision.transforms import InterpolationMode\n\n# Define the transforms\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:44:46.640404Z","iopub.execute_input":"2024-07-17T09:44:46.640707Z","iopub.status.idle":"2024-07-17T09:44:46.653573Z","shell.execute_reply.started":"2024-07-17T09:44:46.640657Z","shell.execute_reply":"2024-07-17T09:44:46.652628Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n\ntrain_dataset = MNISTDataset(train_df, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\ntrain_dataset = MNISTDataset(validation_df, transform=transform)\nval_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:44:46.654692Z","iopub.execute_input":"2024-07-17T09:44:46.654990Z","iopub.status.idle":"2024-07-17T09:44:46.665291Z","shell.execute_reply.started":"2024-07-17T09:44:46.654966Z","shell.execute_reply":"2024-07-17T09:44:46.664562Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"train_dataset.plot_image(0) ","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:44:46.666625Z","iopub.execute_input":"2024-07-17T09:44:46.666919Z","iopub.status.idle":"2024-07-17T09:44:46.776574Z","shell.execute_reply.started":"2024-07-17T09:44:46.666895Z","shell.execute_reply":"2024-07-17T09:44:46.775345Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:44:46.777945Z","iopub.execute_input":"2024-07-17T09:44:46.778319Z","iopub.status.idle":"2024-07-17T09:44:46.783452Z","shell.execute_reply.started":"2024-07-17T09:44:46.778294Z","shell.execute_reply":"2024-07-17T09:44:46.782303Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"class DigitNet(nn.Module):\n    def __init__(self):\n        super(DigitNet, self).__init__()\n        # First block of convolutions and pooling\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  \n        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) \n\n        # Second block of convolutions and pooling\n        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv5 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Correcting the number of input channels for conv6\n        self.conv6 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Fully connected layers\n        self.fc1 = nn.Linear(192 * 3 * 3, 256) \n        self.fc2 = nn.Linear(256, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool1(x)\n        x = F.relu(self.conv4(x))\n        x = F.relu(self.conv5(x))\n        x = self.pool2(x)\n        x = F.relu(self.conv6(x))\n        x = self.pool3(x)\n\n        # Flatten the output for the dense layer\n        x = torch.flatten(x, 1)\n        \n        # Fully connected layers with ReLU activation for the first\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)  # Output layer with logits output, no activation\n        return x\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnet = DigitNet().to(device)\nprint(net)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:44:46.785111Z","iopub.execute_input":"2024-07-17T09:44:46.785839Z","iopub.status.idle":"2024-07-17T09:44:46.814341Z","shell.execute_reply.started":"2024-07-17T09:44:46.785801Z","shell.execute_reply":"2024-07-17T09:44:46.813293Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"DigitNet(\n  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv6): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=1728, out_features=256, bias=True)\n  (fc2): Linear(in_features=256, out_features=10, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.optim.lr_scheduler import CosineAnnealingLR","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:44:46.818275Z","iopub.execute_input":"2024-07-17T09:44:46.818576Z","iopub.status.idle":"2024-07-17T09:44:46.823975Z","shell.execute_reply.started":"2024-07-17T09:44:46.818553Z","shell.execute_reply":"2024-07-17T09:44:46.823330Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(net.parameters(), lr=0.01)\nscheduler = CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=0)  \n\nn_epochs = 12","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:49:13.068879Z","iopub.execute_input":"2024-07-17T09:49:13.069248Z","iopub.status.idle":"2024-07-17T09:49:13.075190Z","shell.execute_reply.started":"2024-07-17T09:49:13.069220Z","shell.execute_reply":"2024-07-17T09:49:13.074230Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"for epoch in range(n_epochs):\n    # Training loop with tqdm\n    net.train()\n    train_losses = []\n    train_correct = 0  # To keep track of correct predictions\n\n    for batch_idx, (images, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n        images, labels = images.to(device), labels.to(device)  \n        optimizer.zero_grad()\n        pred = net(images)\n        loss = loss_fn(pred, labels)\n        loss.backward()\n        optimizer.step()\n        train_losses.append(loss.item())\n        train_correct += (pred.argmax(1) == labels).sum().item()  \n\n    train_accuracy = train_correct / len(train_loader.dataset)\n    avg_train_loss = sum(train_losses) / len(train_losses)\n\n    # Validation loop with tqdm\n    net.eval()\n    val_loss, val_correct = 0, 0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validating\"):\n            images, labels = images.to(device), labels.to(device)\n            pred = net(images)\n            val_loss += loss_fn(pred, labels).item()\n            val_correct += (pred.argmax(1) == labels).sum().item()\n\n    validation_accuracy = val_correct / len(val_loader.dataset)\n    avg_val_loss = val_loss / len(val_loader)\n\n    # Print training and validation results\n    print(f\"Epoch {epoch+1}/{n_epochs}\")\n    print(f\"Training Accuracy = {train_accuracy * 100:.2f}%, Average Loss = {avg_train_loss:.4f}\")\n    print(f\"Validation Accuracy = {validation_accuracy * 100:.2f}%, Average Loss = {avg_val_loss:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:49:13.235085Z","iopub.execute_input":"2024-07-17T09:49:13.236044Z","iopub.status.idle":"2024-07-17T09:54:51.044391Z","shell.execute_reply.started":"2024-07-17T09:49:13.236001Z","shell.execute_reply":"2024-07-17T09:54:51.043427Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"Training: 100%|██████████| 1050/1050 [00:23<00:00, 44.85it/s]\nValidating: 100%|██████████| 263/263 [00:04<00:00, 54.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/12\nTraining Accuracy = 99.29%, Average Loss = 0.0237\nValidation Accuracy = 98.00%, Average Loss = 0.0613\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1050/1050 [00:23<00:00, 44.50it/s]\nValidating: 100%|██████████| 263/263 [00:04<00:00, 56.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/12\nTraining Accuracy = 99.37%, Average Loss = 0.0194\nValidation Accuracy = 98.44%, Average Loss = 0.0526\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1050/1050 [00:22<00:00, 45.87it/s]\nValidating: 100%|██████████| 263/263 [00:04<00:00, 54.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/12\nTraining Accuracy = 99.49%, Average Loss = 0.0170\nValidation Accuracy = 98.43%, Average Loss = 0.0495\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1050/1050 [00:23<00:00, 44.62it/s]\nValidating: 100%|██████████| 263/263 [00:04<00:00, 53.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/12\nTraining Accuracy = 99.60%, Average Loss = 0.0142\nValidation Accuracy = 98.44%, Average Loss = 0.0506\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1050/1050 [00:23<00:00, 45.19it/s]\nValidating: 100%|██████████| 263/263 [00:04<00:00, 53.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/12\nTraining Accuracy = 99.69%, Average Loss = 0.0111\nValidation Accuracy = 98.18%, Average Loss = 0.0632\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1050/1050 [00:23<00:00, 44.72it/s]\nValidating: 100%|██████████| 263/263 [00:04<00:00, 54.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/12\nTraining Accuracy = 99.72%, Average Loss = 0.0101\nValidation Accuracy = 98.25%, Average Loss = 0.0675\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1050/1050 [00:23<00:00, 45.11it/s]\nValidating: 100%|██████████| 263/263 [00:04<00:00, 54.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/12\nTraining Accuracy = 99.73%, Average Loss = 0.0091\nValidation Accuracy = 98.48%, Average Loss = 0.0542\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1050/1050 [00:23<00:00, 44.93it/s]\nValidating: 100%|██████████| 263/263 [00:04<00:00, 53.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/12\nTraining Accuracy = 99.77%, Average Loss = 0.0074\nValidation Accuracy = 98.71%, Average Loss = 0.0504\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1050/1050 [00:23<00:00, 45.10it/s]\nValidating: 100%|██████████| 263/263 [00:04<00:00, 54.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/12\nTraining Accuracy = 99.83%, Average Loss = 0.0057\nValidation Accuracy = 98.55%, Average Loss = 0.0542\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1050/1050 [00:23<00:00, 45.12it/s]\nValidating: 100%|██████████| 263/263 [00:04<00:00, 54.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/12\nTraining Accuracy = 99.89%, Average Loss = 0.0048\nValidation Accuracy = 98.62%, Average Loss = 0.0540\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1050/1050 [00:23<00:00, 45.50it/s]\nValidating: 100%|██████████| 263/263 [00:04<00:00, 55.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/12\nTraining Accuracy = 99.89%, Average Loss = 0.0041\nValidation Accuracy = 98.43%, Average Loss = 0.0598\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1050/1050 [00:23<00:00, 45.09it/s]\nValidating: 100%|██████████| 263/263 [00:04<00:00, 54.52it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 12/12\nTraining Accuracy = 99.94%, Average Loss = 0.0025\nValidation Accuracy = 98.61%, Average Loss = 0.0579\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate and get predictions with classification report\ny_pred, y_true = [], []\nwith torch.no_grad():\n    for images, labels in tqdm(val_loader, desc=\"Evaluating\"):\n        images, labels = images.to(device), labels.to(device)\n        outputs = net(images)\n        y_pred.extend(outputs.argmax(dim=1).tolist())\n        y_true.extend(labels.tolist())\n\nprint(classification_report(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:54:51.046230Z","iopub.execute_input":"2024-07-17T09:54:51.046529Z","iopub.status.idle":"2024-07-17T09:54:55.974440Z","shell.execute_reply.started":"2024-07-17T09:54:51.046504Z","shell.execute_reply":"2024-07-17T09:54:55.973368Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 263/263 [00:04<00:00, 53.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       806\n           1       1.00      0.99      0.99       886\n           2       0.98      0.99      0.98       810\n           3       0.99      0.98      0.98       860\n           4       0.98      0.99      0.99       832\n           5       0.99      0.98      0.98       790\n           6       0.99      0.99      0.99       826\n           7       0.99      0.99      0.99       909\n           8       0.97      0.98      0.98       815\n           9       0.98      0.98      0.98       866\n\n    accuracy                           0.99      8400\n   macro avg       0.99      0.99      0.99      8400\nweighted avg       0.99      0.99      0.99      8400\n\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:54:55.975745Z","iopub.execute_input":"2024-07-17T09:54:55.976141Z","iopub.status.idle":"2024-07-17T09:54:58.063706Z","shell.execute_reply.started":"2024-07-17T09:54:55.976090Z","shell.execute_reply":"2024-07-17T09:54:58.062828Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:54:58.065581Z","iopub.execute_input":"2024-07-17T09:54:58.065878Z","iopub.status.idle":"2024-07-17T09:54:58.084082Z","shell.execute_reply.started":"2024-07-17T09:54:58.065853Z","shell.execute_reply":"2024-07-17T09:54:58.083144Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0       0       0       0       0       0       0       0       0       0   \n1       0       0       0       0       0       0       0       0       0   \n2       0       0       0       0       0       0       0       0       0   \n3       0       0       0       0       0       0       0       0       0   \n4       0       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 784 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 784 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class MNISTTestDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        # Reshape the flat pixel array into 28x28 image\n        image = self.dataframe.iloc[idx].values.reshape(28, 28, 1).astype(np.uint8)\n        if self.transform:\n            image = self.transform(image)\n        return image","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:54:58.085380Z","iopub.execute_input":"2024-07-17T09:54:58.085805Z","iopub.status.idle":"2024-07-17T09:54:58.094258Z","shell.execute_reply.started":"2024-07-17T09:54:58.085771Z","shell.execute_reply":"2024-07-17T09:54:58.093400Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"test_transform = transforms.Compose([\n    transforms.ToPILImage(),  # Because the numpy array needs to be converted to PIL Image\n    transforms.ToTensor(),    # Converts to Tensor and scales to [0,1]\n    transforms.Normalize((0.5,), (0.5,))  # Normalize the images\n])\n\n\ndf_test = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n\n\ntest_dataset = MNISTTestDataset(df_test, transform=test_transform)\n\n\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)  # Shuffle is False for test data\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnet.to(device)\nnet.eval()  \n\n\npredictions = []\n\nwith torch.no_grad():\n    for images in tqdm(test_loader, desc=\"Predicting\"):\n        images = images.to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\n\nsubmission = pd.DataFrame({\n    'ImageId': np.arange(1, len(predictions) + 1),\n    'Label': predictions\n})\n\n\nsubmission.to_csv('mnist_predictions.csv', index=False)\nprint(\"Saved predictions to 'mnist_predictions.csv'\")","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:54:58.095351Z","iopub.execute_input":"2024-07-17T09:54:58.095690Z","iopub.status.idle":"2024-07-17T09:55:09.439335Z","shell.execute_reply.started":"2024-07-17T09:54:58.095667Z","shell.execute_reply":"2024-07-17T09:55:09.438417Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"Predicting: 100%|██████████| 438/438 [00:09<00:00, 45.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved predictions to 'mnist_predictions.csv'\n","output_type":"stream"}]}]}